{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804edaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import warnings\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "from datasets import Dataset,load_dataset, load_from_disk\n",
    "from datasets import load_metric, disable_progress_bar\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.disable(logging.ERROR)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5e02461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b9047</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>814d6b</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "1    3b9047  In complete sentences, summarize the structure...   \n",
       "2    814d6b  Summarize how the Third Wave developed over su...   \n",
       "3    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "                prompt_title  \\\n",
       "0                 On Tragedy   \n",
       "1  Egyptian Social Structure   \n",
       "2             The Third Wave   \n",
       "3    Excerpt from The Jungle   \n",
       "\n",
       "                                         prompt_text  \n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...  \n",
       "1  Egyptian society was structured like a pyramid...  \n",
       "2  Background \\r\\nThe Third Wave experiment took ...  \n",
       "3  With one member trimming beef in a cannery, an...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'C:/Users/shaur/Downloads/commonlit-evaluate-student-summaries'\n",
    "\n",
    "prompts_train = pd.read_csv(f'{PATH}/prompts_train.csv')\n",
    "prompts_test = pd.read_csv(f'{PATH}/prompts_test.csv')\n",
    "\n",
    "summaries_train = pd.read_csv(f'{PATH}/summaries_train.csv')\n",
    "summaries_test = pd.read_csv(f'{PATH}/summaries_test.csv')\n",
    "\n",
    "sample_submission = pd.read_csv(f'{PATH}/sample_submission.csv')\n",
    "\n",
    "prompts_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03c80aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = summaries_train.merge(prompts_train, how=\"left\", on=\"prompt_id\")#[:2000]\n",
    "test = summaries_test.merge(prompts_test, how=\"left\", on=\"prompt_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8365bb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7165 entries, 0 to 7164\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   student_id       7165 non-null   object \n",
      " 1   prompt_id        7165 non-null   object \n",
      " 2   text             7165 non-null   object \n",
      " 3   content          7165 non-null   float64\n",
      " 4   wording          7165 non-null   float64\n",
      " 5   prompt_question  7165 non-null   object \n",
      " 6   prompt_title     7165 non-null   object \n",
      " 7   prompt_text      7165 non-null   object \n",
      "dtypes: float64(2), object(6)\n",
      "memory usage: 447.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e30fe44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id                                               text  \\\n",
       "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
       "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
       "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
       "3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n",
       "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
       "\n",
       "    content   wording                                    prompt_question  \\\n",
       "0  0.205683  0.380538  Summarize how the Third Wave developed over su...   \n",
       "1 -0.548304  0.506755  Summarize the various ways the factory would u...   \n",
       "2  3.128928  4.231226  In complete sentences, summarize the structure...   \n",
       "3 -0.210614 -0.471415  In complete sentences, summarize the structure...   \n",
       "4  3.272894  3.219757  Summarize how the Third Wave developed over su...   \n",
       "\n",
       "                prompt_title  \\\n",
       "0             The Third Wave   \n",
       "1    Excerpt from The Jungle   \n",
       "2  Egyptian Social Structure   \n",
       "3  Egyptian Social Structure   \n",
       "4             The Third Wave   \n",
       "\n",
       "                                         prompt_text  \n",
       "0  Background \\r\\nThe Third Wave experiment took ...  \n",
       "1  With one member trimming beef in a cannery, an...  \n",
       "2  Egyptian society was structured like a pyramid...  \n",
       "3  Egyptian society was structured like a pyramid...  \n",
       "4  Background \\r\\nThe Third Wave experiment took ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a9272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mcrmse(eval_pred):\n",
    "    \"\"\"\n",
    "    Calculates mean columnwise root mean squared error\n",
    "    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n",
    "    \"\"\"\n",
    "    preds, labels = eval_pred\n",
    "\n",
    "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
    "    mcrmse = np.mean(col_rmse)\n",
    "\n",
    "    return {\n",
    "        \"content_rmse\": col_rmse[0],\n",
    "        \"wording_rmse\": col_rmse[1],\n",
    "        \"mcrmse\": mcrmse,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a42ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    model_name=\"roberta-base\"\n",
    "    learning_rate=1.2e-5\n",
    "    warmup_ratio=0.01\n",
    "    weight_decay=0.02\n",
    "    hidden_dropout_prob=0.01\n",
    "    attention_probs_dropout_prob=0.01\n",
    "    num_layers_to_freeze=100\n",
    "    num_train_epochs=3\n",
    "    n_splits=4\n",
    "    batch_size=9\n",
    "    random_seed=42\n",
    "    save_steps=70\n",
    "    max_length=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01d7886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_n_infer(train,\n",
    "                 val,\n",
    "                 model_name,\n",
    "                 batch_size,\n",
    "                 learning_rate,\n",
    "                 warmup_ratio,\n",
    "                  weight_decay,\n",
    "                 hidden_dropout_prob,\n",
    "                 attention_probs_dropoup_prob,\n",
    "#                  num_layers_to_freeze,\n",
    "                 num_train_epochs,\n",
    "                 save_steps,\n",
    "                 random_seed,\n",
    "                 max_length,\n",
    "                 model_dir):\n",
    "    train_content = train[[\"text\",\"content\",\"wording\"]]\n",
    "    val_content = val[[\"text\",\"content\",\"wording\"]]\n",
    "    test_content = test[[\"text\"]]\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model_config = AutoConfig.from_pretrained(model_name)\n",
    "    model_config.update({\n",
    "        \"num_labels\":2,\n",
    "        \"problem_type\":\"regression\"\n",
    "    })\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else cpu)\n",
    "    model_content = AutoModelForSequenceClassification.from_pretrained(model_name, config=model_config).to(device)\n",
    "    \n",
    "#     for name, param in list(model_content.named_parameters())[: num_layers_to_freeze]:\n",
    "#         param.requires_grad = False\n",
    "    \n",
    "    def tokenize_function(examples):\n",
    "        labels = [examples[\"content\"], examples[\"wording\"]]\n",
    "        tokenized = tokenizer(examples[\"text\"],\n",
    "                         padding=False,\n",
    "                         truncation=True,\n",
    "                         max_length=max_length)\n",
    "        return {\n",
    "            **tokenized,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "    \n",
    "    def tokenize_function_test(examples):\n",
    "        tokenized = tokenizer(examples[\"text\"],\n",
    "                         padding=False,\n",
    "                         truncation=True,\n",
    "                         max_length=max_length)\n",
    "        return tokenized\n",
    "    train_dataset_content = Dataset.from_pandas(train_content, preserve_index=False) \n",
    "    val_dataset_content = Dataset.from_pandas(val_content, preserve_index=False)\n",
    "    \n",
    "    train_tokenized_datasets_content = train_dataset_content.map(tokenize_function, batched=False)\n",
    "    val_tokenized_datasets_content = val_dataset_content.map(tokenize_function, batched=False)\n",
    "\n",
    "    test_dataset = Dataset.from_pandas(test_content, preserve_index=False) \n",
    "    test_tokenized_dataset = test_dataset.map(tokenize_function_test, batched=False)\n",
    "    \n",
    "    data_collator = DataCollatorWithPadding(\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                      load_best_model_at_end=True,\n",
    "                                      learning_rate=learning_rate,\n",
    "                                      warmup_ratio=warmup_ratio,\n",
    "                                      per_device_train_batch_size=batch_size,\n",
    "                                      per_device_eval_batch_size=8,\n",
    "                                      num_train_epochs=num_train_epochs,\n",
    "                                      weight_decay=weight_decay,\n",
    "                                      report_to='none',\n",
    "                                      disable_tqdm=True,\n",
    "#                                       greater_is_better=False,\n",
    "                                      save_strategy=\"steps\",\n",
    "                                      evaluation_strategy=\"steps\",\n",
    "                                      eval_steps=save_steps,\n",
    "                                      save_steps=save_steps,\n",
    "                                      metric_for_best_model=\"mcrmse\",\n",
    "                                      save_total_limit=5\n",
    "                                     )\n",
    "    trainer_content = Trainer(\n",
    "        model=model_content,\n",
    "        args=training_args,\n",
    "        train_dataset=train_tokenized_datasets_content,\n",
    "        eval_dataset=val_tokenized_datasets_content,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_mcrmse,#compute_metrics,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "    trainer_content.train()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    best_check = os.listdir(model_dir)[0]\n",
    "    model_content = AutoModelForSequenceClassification.from_pretrained(f\"{model_dir}/{best_check}\")\n",
    "    model_content.eval()\n",
    "\n",
    "    test_args = TrainingArguments(\n",
    "        output_dir=model_dir,\n",
    "        do_train = False,\n",
    "        do_predict = True,\n",
    "        per_device_eval_batch_size = 4,   \n",
    "        dataloader_drop_last = False,\n",
    "    )\n",
    "\n",
    "    # init trainer\n",
    "    infer_content = Trainer(\n",
    "                  model = model_content, \n",
    "                  tokenizer=tokenizer,\n",
    "                  data_collator=data_collator,\n",
    "                  args = test_args)\n",
    "\n",
    "    val_results_content = infer_content.predict(val_tokenized_datasets_content)[0]\n",
    "    test_results_content = infer_content.predict(test_tokenized_dataset)[0]\n",
    "    \n",
    "    model_content.save_pretrained(model_dir)\n",
    "    tokenizer.save_pretrained(model_dir)\n",
    "    \n",
    "#     try:\n",
    "#         shutil.rmtree(f\"{model_dir}/{best_check}\")\n",
    "#     except Exception:\n",
    "#         pass\n",
    "#     time.sleep(5)\n",
    "\n",
    "    return val_results_content, test_results_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99b56104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof_pred_n_test(train,\n",
    "                       model_name,\n",
    "                       n_splits,\n",
    "                       batch_size,\n",
    "                       learning_rate,\n",
    "                        warmup_ratio,\n",
    "                        hidden_dropout_prob,\n",
    "                        attention_probs_dropout_prob,\n",
    "                        num_layers_to_freeze,\n",
    "                        weight_decay,\n",
    "                        num_train_epochs,\n",
    "                        random_seed,\n",
    "                        save_steps,\n",
    "                        max_length\n",
    "                       ):\n",
    "    kf1 = GroupKFold(n_splits)\n",
    "    oof_content = np.zeros((len(train), 2))\n",
    "    test_pred_content = np.zeros((len(test), 2))\n",
    "    \n",
    "    model_name_ = model_name+\"12\"\n",
    "    if not os.path.exists(model_name_):\n",
    "        try:\n",
    "            os.mkdir(model_name_)\n",
    "        except Exception:\n",
    "            pass\n",
    "    time.sleep(5)\n",
    "    \n",
    "    for i, (train_indx, val_indx) in enumerate(kf1.split(train,  groups=train[\"prompt_id\"])):\n",
    "        print(f\"fold {i}:\")\n",
    "        train_ = train.iloc[train_indx]\n",
    "        val_ = train.iloc[val_indx]\n",
    "        \n",
    "        val_res_content, test_res_content = train_n_infer(train_,\n",
    "                                                         val_,\n",
    "                                                         model_name,\n",
    "                                                         batch_size,\n",
    "                                                         learning_rate,\n",
    "                                                         warmup_ratio,\n",
    "                                                         hidden_dropout_prob,\n",
    "                                                          attention_probs_dropout_prob,\n",
    "                                                          weight_decay,\n",
    "                                                          num_train_epochs,\n",
    "                                                          save_steps,\n",
    "                                                          random_seed,\n",
    "                                                          max_length,\n",
    "                                                          model_dir=f\"{model_name_}/fold_{i}\"\n",
    "                                                         )\n",
    "        oof_content[val_indx] = val_res_content\n",
    "        test_pred_content += test_res_content/n_splits\n",
    "    \n",
    "    oof_train = pd.DataFrame(oof_content, columns=[f\"content_pred_{model_name_}\", f\"wording_pred_{model_name_}\"])\n",
    "    test_pred = pd.DataFrame(test_pred_content, columns=[f\"content_pred_{model_name_}\", f\"wording_pred_{model_name_}\"])\n",
    "\n",
    "    cv_metric = compute_mcrmse((oof_train.values, train[[\"content\", \"wording\"]]))\n",
    "    print(f\"cv mcrmse: {cv_metric}\")\n",
    "    with open(f\"{model_name_}/cv_metric.json\", \"w\") as outfile:\n",
    "        json.dump(cv_metric, outfile)\n",
    "        \n",
    "    oof_train.to_csv(f\"{model_name_}/oof_train.csv\", index=False)\n",
    "    test_pred.to_csv(f\"test_pred.csv\", index=False)\n",
    "    \n",
    "    return oof_train, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92781019",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0:\n",
      "{'eval_loss': 0.5523695349693298, 'eval_content_rmse': 0.5763614177703857, 'eval_wording_rmse': 0.8789457082748413, 'eval_mcrmse': 0.7276535630226135, 'eval_runtime': 21.9721, 'eval_samples_per_second': 93.619, 'eval_steps_per_second': 11.742, 'epoch': 0.12}\n",
      "{'eval_loss': 0.33143454790115356, 'eval_content_rmse': 0.4698494076728821, 'eval_wording_rmse': 0.6649138927459717, 'eval_mcrmse': 0.5673816204071045, 'eval_runtime': 20.5876, 'eval_samples_per_second': 99.914, 'eval_steps_per_second': 12.532, 'epoch': 0.25}\n",
      "{'eval_loss': 0.36663180589675903, 'eval_content_rmse': 0.5179646611213684, 'eval_wording_rmse': 0.6818918585777283, 'eval_mcrmse': 0.5999282598495483, 'eval_runtime': 21.726, 'eval_samples_per_second': 94.679, 'eval_steps_per_second': 11.875, 'epoch': 0.37}\n",
      "{'eval_loss': 0.31590697169303894, 'eval_content_rmse': 0.46712514758110046, 'eval_wording_rmse': 0.6431236863136292, 'eval_mcrmse': 0.5551244020462036, 'eval_runtime': 21.7343, 'eval_samples_per_second': 94.643, 'eval_steps_per_second': 11.871, 'epoch': 0.49}\n",
      "{'eval_loss': 0.31632405519485474, 'eval_content_rmse': 0.4699876010417938, 'eval_wording_rmse': 0.6416849493980408, 'eval_mcrmse': 0.5558362603187561, 'eval_runtime': 21.9729, 'eval_samples_per_second': 93.615, 'eval_steps_per_second': 11.742, 'epoch': 0.62}\n",
      "{'eval_loss': 0.3947582542896271, 'eval_content_rmse': 0.5732826590538025, 'eval_wording_rmse': 0.6788691282272339, 'eval_mcrmse': 0.6260758638381958, 'eval_runtime': 21.3886, 'eval_samples_per_second': 96.173, 'eval_steps_per_second': 12.062, 'epoch': 0.74}\n",
      "{'eval_loss': 0.34571847319602966, 'eval_content_rmse': 0.5026387572288513, 'eval_wording_rmse': 0.6624129414558411, 'eval_mcrmse': 0.5825258493423462, 'eval_runtime': 21.2633, 'eval_samples_per_second': 96.74, 'eval_steps_per_second': 12.134, 'epoch': 0.86}\n",
      "{'loss': 0.4632, 'learning_rate': 8.569395017793595e-06, 'epoch': 0.88}\n",
      "{'eval_loss': 0.29622599482536316, 'eval_content_rmse': 0.48948541283607483, 'eval_wording_rmse': 0.5940167903900146, 'eval_mcrmse': 0.5417510867118835, 'eval_runtime': 20.8425, 'eval_samples_per_second': 98.692, 'eval_steps_per_second': 12.379, 'epoch': 0.99}\n",
      "{'eval_loss': 0.29581156373023987, 'eval_content_rmse': 0.4855608344078064, 'eval_wording_rmse': 0.5965348482131958, 'eval_mcrmse': 0.5410478115081787, 'eval_runtime': 20.5472, 'eval_samples_per_second': 100.111, 'eval_steps_per_second': 12.556, 'epoch': 1.11}\n",
      "{'eval_loss': 0.32267069816589355, 'eval_content_rmse': 0.4249025285243988, 'eval_wording_rmse': 0.6817618608474731, 'eval_mcrmse': 0.5533322095870972, 'eval_runtime': 20.5789, 'eval_samples_per_second': 99.957, 'eval_steps_per_second': 12.537, 'epoch': 1.23}\n",
      "{'eval_loss': 0.30812641978263855, 'eval_content_rmse': 0.4558212459087372, 'eval_wording_rmse': 0.6391245722770691, 'eval_mcrmse': 0.5474728941917419, 'eval_runtime': 20.5423, 'eval_samples_per_second': 100.135, 'eval_steps_per_second': 12.559, 'epoch': 1.36}\n",
      "{'eval_loss': 0.3072492480278015, 'eval_content_rmse': 0.5201486945152283, 'eval_wording_rmse': 0.5864672064781189, 'eval_mcrmse': 0.5533079504966736, 'eval_runtime': 20.5513, 'eval_samples_per_second': 100.091, 'eval_steps_per_second': 12.554, 'epoch': 1.48}\n",
      "{'eval_loss': 0.2979547679424286, 'eval_content_rmse': 0.414326936006546, 'eval_wording_rmse': 0.6513391733169556, 'eval_mcrmse': 0.5328330397605896, 'eval_runtime': 20.5325, 'eval_samples_per_second': 100.183, 'eval_steps_per_second': 12.565, 'epoch': 1.6}\n",
      "{'eval_loss': 0.30542901158332825, 'eval_content_rmse': 0.44909238815307617, 'eval_wording_rmse': 0.639667272567749, 'eval_mcrmse': 0.5443798303604126, 'eval_runtime': 20.6682, 'eval_samples_per_second': 99.525, 'eval_steps_per_second': 12.483, 'epoch': 1.73}\n",
      "{'loss': 0.2798, 'learning_rate': 5.01067615658363e-06, 'epoch': 1.76}\n",
      "{'eval_loss': 0.28515341877937317, 'eval_content_rmse': 0.5069712996482849, 'eval_wording_rmse': 0.5597205758094788, 'eval_mcrmse': 0.5333459377288818, 'eval_runtime': 20.6913, 'eval_samples_per_second': 99.414, 'eval_steps_per_second': 12.469, 'epoch': 1.85}\n",
      "{'eval_loss': 0.3044559061527252, 'eval_content_rmse': 0.4194052517414093, 'eval_wording_rmse': 0.6580359935760498, 'eval_mcrmse': 0.5387206077575684, 'eval_runtime': 20.7813, 'eval_samples_per_second': 98.983, 'eval_steps_per_second': 12.415, 'epoch': 1.97}\n",
      "{'eval_loss': 0.3191491365432739, 'eval_content_rmse': 0.4217529296875, 'eval_wording_rmse': 0.6785445809364319, 'eval_mcrmse': 0.5501487255096436, 'eval_runtime': 20.9602, 'eval_samples_per_second': 98.139, 'eval_steps_per_second': 12.309, 'epoch': 2.1}\n",
      "{'eval_loss': 0.2858061194419861, 'eval_content_rmse': 0.4332258403301239, 'eval_wording_rmse': 0.6196187734603882, 'eval_mcrmse': 0.5264223217964172, 'eval_runtime': 20.9458, 'eval_samples_per_second': 98.206, 'eval_steps_per_second': 12.318, 'epoch': 2.22}\n",
      "{'eval_loss': 0.3622862994670868, 'eval_content_rmse': 0.41292500495910645, 'eval_wording_rmse': 0.744355320930481, 'eval_mcrmse': 0.5786401629447937, 'eval_runtime': 20.8685, 'eval_samples_per_second': 98.569, 'eval_steps_per_second': 12.363, 'epoch': 2.34}\n",
      "{'eval_loss': 0.2895517349243164, 'eval_content_rmse': 0.47868916392326355, 'eval_wording_rmse': 0.5915744304656982, 'eval_mcrmse': 0.5351318120956421, 'eval_runtime': 20.7902, 'eval_samples_per_second': 98.941, 'eval_steps_per_second': 12.41, 'epoch': 2.46}\n",
      "{'eval_loss': 0.3185736835002899, 'eval_content_rmse': 0.40971633791923523, 'eval_wording_rmse': 0.6850400567054749, 'eval_mcrmse': 0.5473781824111938, 'eval_runtime': 20.9642, 'eval_samples_per_second': 98.119, 'eval_steps_per_second': 12.307, 'epoch': 2.59}\n",
      "{'loss': 0.2341, 'learning_rate': 1.4519572953736654e-06, 'epoch': 2.64}\n",
      "{'eval_loss': 0.32622984051704407, 'eval_content_rmse': 0.41222625970840454, 'eval_wording_rmse': 0.6946432590484619, 'eval_mcrmse': 0.5534347295761108, 'eval_runtime': 20.9321, 'eval_samples_per_second': 98.27, 'eval_steps_per_second': 12.326, 'epoch': 2.71}\n",
      "{'eval_loss': 0.3267601728439331, 'eval_content_rmse': 0.4606296420097351, 'eval_wording_rmse': 0.6643346548080444, 'eval_mcrmse': 0.5624821186065674, 'eval_runtime': 20.9446, 'eval_samples_per_second': 98.211, 'eval_steps_per_second': 12.318, 'epoch': 2.83}\n",
      "{'eval_loss': 0.311129629611969, 'eval_content_rmse': 0.4342866539955139, 'eval_wording_rmse': 0.6585243344306946, 'eval_mcrmse': 0.5464054942131042, 'eval_runtime': 22.1463, 'eval_samples_per_second': 92.882, 'eval_steps_per_second': 11.65, 'epoch': 2.96}\n",
      "{'train_runtime': 1885.0142, 'train_samples_per_second': 8.129, 'train_steps_per_second': 0.904, 'train_loss': 0.3118868098012718, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1:\n",
      "{'eval_loss': 0.5616319179534912, 'eval_content_rmse': 0.6678569912910461, 'eval_wording_rmse': 0.822939932346344, 'eval_mcrmse': 0.7453984618186951, 'eval_runtime': 25.3802, 'eval_samples_per_second': 79.156, 'eval_steps_per_second': 9.929, 'epoch': 0.12}\n",
      "{'eval_loss': 0.5942267179489136, 'eval_content_rmse': 0.5917056202888489, 'eval_wording_rmse': 0.9156083464622498, 'eval_mcrmse': 0.7536569833755493, 'eval_runtime': 30.538, 'eval_samples_per_second': 65.787, 'eval_steps_per_second': 8.252, 'epoch': 0.24}\n",
      "{'eval_loss': 0.5398957133293152, 'eval_content_rmse': 0.613020658493042, 'eval_wording_rmse': 0.839045524597168, 'eval_mcrmse': 0.726033091545105, 'eval_runtime': 30.6544, 'eval_samples_per_second': 65.537, 'eval_steps_per_second': 8.221, 'epoch': 0.37}\n",
      "{'eval_loss': 0.6434057950973511, 'eval_content_rmse': 0.7209590673446655, 'eval_wording_rmse': 0.8758023381233215, 'eval_mcrmse': 0.7983807325363159, 'eval_runtime': 48.2202, 'eval_samples_per_second': 41.663, 'eval_steps_per_second': 5.226, 'epoch': 0.49}\n",
      "{'eval_loss': 0.6026370525360107, 'eval_content_rmse': 0.5614321231842041, 'eval_wording_rmse': 0.9434347748756409, 'eval_mcrmse': 0.7524334192276001, 'eval_runtime': 48.1841, 'eval_samples_per_second': 41.694, 'eval_steps_per_second': 5.23, 'epoch': 0.61}\n",
      "{'eval_loss': 0.6170167326927185, 'eval_content_rmse': 0.5605696439743042, 'eval_wording_rmse': 0.959059476852417, 'eval_mcrmse': 0.7598145604133606, 'eval_runtime': 48.2189, 'eval_samples_per_second': 41.664, 'eval_steps_per_second': 5.226, 'epoch': 0.73}\n",
      "{'eval_loss': 0.5666716694831848, 'eval_content_rmse': 0.5412999391555786, 'eval_wording_rmse': 0.9166989326477051, 'eval_mcrmse': 0.7289994359016418, 'eval_runtime': 48.2673, 'eval_samples_per_second': 41.622, 'eval_steps_per_second': 5.221, 'epoch': 0.86}\n",
      "{'loss': 0.4174, 'learning_rate': 8.599647266313933e-06, 'epoch': 0.87}\n",
      "{'eval_loss': 0.5468047857284546, 'eval_content_rmse': 0.5712414979934692, 'eval_wording_rmse': 0.8759526014328003, 'eval_mcrmse': 0.7235970497131348, 'eval_runtime': 48.3591, 'eval_samples_per_second': 41.543, 'eval_steps_per_second': 5.211, 'epoch': 0.98}\n",
      "{'eval_loss': 0.5254274010658264, 'eval_content_rmse': 0.5713862776756287, 'eval_wording_rmse': 0.8511006832122803, 'eval_mcrmse': 0.7112435102462769, 'eval_runtime': 48.3507, 'eval_samples_per_second': 41.551, 'eval_steps_per_second': 5.212, 'epoch': 1.1}\n",
      "{'eval_loss': 0.5390713810920715, 'eval_content_rmse': 0.5457348227500916, 'eval_wording_rmse': 0.8833552598953247, 'eval_mcrmse': 0.7145450115203857, 'eval_runtime': 48.262, 'eval_samples_per_second': 41.627, 'eval_steps_per_second': 5.222, 'epoch': 1.22}\n",
      "{'eval_loss': 0.5480813384056091, 'eval_content_rmse': 0.5435248017311096, 'eval_wording_rmse': 0.8948429822921753, 'eval_mcrmse': 0.7191839218139648, 'eval_runtime': 48.2187, 'eval_samples_per_second': 41.664, 'eval_steps_per_second': 5.226, 'epoch': 1.34}\n",
      "{'eval_loss': 0.4672660827636719, 'eval_content_rmse': 0.5778034925460815, 'eval_wording_rmse': 0.7750325798988342, 'eval_mcrmse': 0.6764180660247803, 'eval_runtime': 48.1885, 'eval_samples_per_second': 41.69, 'eval_steps_per_second': 5.229, 'epoch': 1.47}\n",
      "{'eval_loss': 0.4876899719238281, 'eval_content_rmse': 0.5342803597450256, 'eval_wording_rmse': 0.8306171894073486, 'eval_mcrmse': 0.6824487447738647, 'eval_runtime': 48.2789, 'eval_samples_per_second': 41.612, 'eval_steps_per_second': 5.22, 'epoch': 1.59}\n",
      "{'eval_loss': 0.4845317602157593, 'eval_content_rmse': 0.5449666380882263, 'eval_wording_rmse': 0.8198019862174988, 'eval_mcrmse': 0.6823843121528625, 'eval_runtime': 48.1824, 'eval_samples_per_second': 41.696, 'eval_steps_per_second': 5.23, 'epoch': 1.71}\n",
      "{'loss': 0.246, 'learning_rate': 5.072310405643739e-06, 'epoch': 1.75}\n",
      "{'eval_loss': 0.48877981305122375, 'eval_content_rmse': 0.5357785820960999, 'eval_wording_rmse': 0.8309637904167175, 'eval_mcrmse': 0.6833711862564087, 'eval_runtime': 48.2942, 'eval_samples_per_second': 41.599, 'eval_steps_per_second': 5.218, 'epoch': 1.83}\n",
      "{'eval_loss': 0.4501296281814575, 'eval_content_rmse': 0.5307415127754211, 'eval_wording_rmse': 0.7864940166473389, 'eval_mcrmse': 0.6586177349090576, 'eval_runtime': 48.2033, 'eval_samples_per_second': 41.678, 'eval_steps_per_second': 5.228, 'epoch': 1.95}\n",
      "{'eval_loss': 0.5288506150245667, 'eval_content_rmse': 0.5358723998069763, 'eval_wording_rmse': 0.8778051733970642, 'eval_mcrmse': 0.7068387866020203, 'eval_runtime': 48.1863, 'eval_samples_per_second': 41.692, 'eval_steps_per_second': 5.23, 'epoch': 2.08}\n",
      "{'eval_loss': 0.5416696071624756, 'eval_content_rmse': 0.5403428077697754, 'eval_wording_rmse': 0.8895893692970276, 'eval_mcrmse': 0.7149660587310791, 'eval_runtime': 48.3481, 'eval_samples_per_second': 41.553, 'eval_steps_per_second': 5.212, 'epoch': 2.2}\n",
      "{'eval_loss': 0.5534418821334839, 'eval_content_rmse': 0.5363293886184692, 'eval_wording_rmse': 0.9051156640052795, 'eval_mcrmse': 0.7207225561141968, 'eval_runtime': 48.3505, 'eval_samples_per_second': 41.551, 'eval_steps_per_second': 5.212, 'epoch': 2.32}\n",
      "{'eval_loss': 0.546337366104126, 'eval_content_rmse': 0.5311421751976013, 'eval_wording_rmse': 0.9003124237060547, 'eval_mcrmse': 0.7157273292541504, 'eval_runtime': 48.208, 'eval_samples_per_second': 41.674, 'eval_steps_per_second': 5.227, 'epoch': 2.44}\n",
      "{'eval_loss': 0.5092185735702515, 'eval_content_rmse': 0.5343765020370483, 'eval_wording_rmse': 0.856083869934082, 'eval_mcrmse': 0.6952301859855652, 'eval_runtime': 48.1128, 'eval_samples_per_second': 41.756, 'eval_steps_per_second': 5.238, 'epoch': 2.57}\n",
      "{'loss': 0.2013, 'learning_rate': 1.544973544973545e-06, 'epoch': 2.62}\n",
      "{'eval_loss': 0.5207588076591492, 'eval_content_rmse': 0.5329275727272034, 'eval_wording_rmse': 0.8703476786613464, 'eval_mcrmse': 0.7016376256942749, 'eval_runtime': 48.171, 'eval_samples_per_second': 41.706, 'eval_steps_per_second': 5.231, 'epoch': 2.69}\n",
      "{'eval_loss': 0.5282411575317383, 'eval_content_rmse': 0.5335448980331421, 'eval_wording_rmse': 0.8785286545753479, 'eval_mcrmse': 0.7060368061065674, 'eval_runtime': 48.3102, 'eval_samples_per_second': 41.585, 'eval_steps_per_second': 5.216, 'epoch': 2.81}\n",
      "{'eval_loss': 0.5242999792098999, 'eval_content_rmse': 0.5311528444290161, 'eval_wording_rmse': 0.8754865527153015, 'eval_mcrmse': 0.7033196687698364, 'eval_runtime': 48.241, 'eval_samples_per_second': 41.645, 'eval_steps_per_second': 5.224, 'epoch': 2.93}\n",
      "{'train_runtime': 2708.5314, 'train_samples_per_second': 5.711, 'train_steps_per_second': 0.635, 'train_loss': 0.2754175431371914, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2:\n",
      "{'eval_loss': 0.7648281455039978, 'eval_content_rmse': 0.8080994486808777, 'eval_wording_rmse': 0.9362862706184387, 'eval_mcrmse': 0.8721928596496582, 'eval_runtime': 26.5362, 'eval_samples_per_second': 75.218, 'eval_steps_per_second': 9.421, 'epoch': 0.12}\n",
      "{'eval_loss': 0.44533291459083557, 'eval_content_rmse': 0.5820702910423279, 'eval_wording_rmse': 0.7428726553916931, 'eval_mcrmse': 0.6624714732170105, 'eval_runtime': 27.3911, 'eval_samples_per_second': 72.87, 'eval_steps_per_second': 9.127, 'epoch': 0.24}\n",
      "{'eval_loss': 0.4338538348674774, 'eval_content_rmse': 0.549263060092926, 'eval_wording_rmse': 0.7523418664932251, 'eval_mcrmse': 0.650802493095398, 'eval_runtime': 31.3691, 'eval_samples_per_second': 63.629, 'eval_steps_per_second': 7.97, 'epoch': 0.37}\n",
      "{'eval_loss': 0.43823450803756714, 'eval_content_rmse': 0.5028978586196899, 'eval_wording_rmse': 0.7896600961685181, 'eval_mcrmse': 0.646278977394104, 'eval_runtime': 31.3241, 'eval_samples_per_second': 63.721, 'eval_steps_per_second': 7.981, 'epoch': 0.49}\n",
      "{'eval_loss': 0.38211214542388916, 'eval_content_rmse': 0.5886653065681458, 'eval_wording_rmse': 0.6462951302528381, 'eval_mcrmse': 0.6174802184104919, 'eval_runtime': 31.2813, 'eval_samples_per_second': 63.808, 'eval_steps_per_second': 7.992, 'epoch': 0.61}\n",
      "{'eval_loss': 0.41741934418678284, 'eval_content_rmse': 0.5420857667922974, 'eval_wording_rmse': 0.7355147004127502, 'eval_mcrmse': 0.6388002634048462, 'eval_runtime': 31.3314, 'eval_samples_per_second': 63.706, 'eval_steps_per_second': 7.979, 'epoch': 0.73}\n",
      "{'eval_loss': 0.4219653308391571, 'eval_content_rmse': 0.6101474165916443, 'eval_wording_rmse': 0.6867680549621582, 'eval_mcrmse': 0.6484577655792236, 'eval_runtime': 31.3124, 'eval_samples_per_second': 63.745, 'eval_steps_per_second': 7.984, 'epoch': 0.85}\n",
      "{'loss': 0.4472, 'learning_rate': 8.611599297012302e-06, 'epoch': 0.87}\n",
      "{'eval_loss': 0.41634881496429443, 'eval_content_rmse': 0.5587695240974426, 'eval_wording_rmse': 0.7214393615722656, 'eval_mcrmse': 0.6401044130325317, 'eval_runtime': 31.343, 'eval_samples_per_second': 63.683, 'eval_steps_per_second': 7.976, 'epoch': 0.97}\n",
      "{'eval_loss': 0.38222697377204895, 'eval_content_rmse': 0.5699803829193115, 'eval_wording_rmse': 0.6630055904388428, 'eval_mcrmse': 0.6164929866790771, 'eval_runtime': 31.1579, 'eval_samples_per_second': 64.061, 'eval_steps_per_second': 8.024, 'epoch': 1.1}\n",
      "{'eval_loss': 0.3935418128967285, 'eval_content_rmse': 0.508971095085144, 'eval_wording_rmse': 0.7266581058502197, 'eval_mcrmse': 0.6178146004676819, 'eval_runtime': 31.5318, 'eval_samples_per_second': 63.301, 'eval_steps_per_second': 7.928, 'epoch': 1.22}\n",
      "{'eval_loss': 0.3918019235134125, 'eval_content_rmse': 0.5495337843894958, 'eval_wording_rmse': 0.6939859986305237, 'eval_mcrmse': 0.6217598915100098, 'eval_runtime': 31.2832, 'eval_samples_per_second': 63.804, 'eval_steps_per_second': 7.992, 'epoch': 1.34}\n",
      "{'eval_loss': 0.3560205101966858, 'eval_content_rmse': 0.5308553576469421, 'eval_wording_rmse': 0.6559216976165771, 'eval_mcrmse': 0.593388557434082, 'eval_runtime': 31.2396, 'eval_samples_per_second': 63.893, 'eval_steps_per_second': 8.003, 'epoch': 1.46}\n",
      "{'eval_loss': 0.34898555278778076, 'eval_content_rmse': 0.49480965733528137, 'eval_wording_rmse': 0.6731523275375366, 'eval_mcrmse': 0.5839809775352478, 'eval_runtime': 31.3415, 'eval_samples_per_second': 63.686, 'eval_steps_per_second': 7.977, 'epoch': 1.58}\n",
      "{'eval_loss': 0.32929474115371704, 'eval_content_rmse': 0.5196344256401062, 'eval_wording_rmse': 0.6233532428741455, 'eval_mcrmse': 0.5714938640594482, 'eval_runtime': 31.3429, 'eval_samples_per_second': 63.683, 'eval_steps_per_second': 7.976, 'epoch': 1.7}\n",
      "{'loss': 0.2936, 'learning_rate': 5.096660808435853e-06, 'epoch': 1.74}\n",
      "{'eval_loss': 0.37194952368736267, 'eval_content_rmse': 0.5152555108070374, 'eval_wording_rmse': 0.6916725039482117, 'eval_mcrmse': 0.6034640073776245, 'eval_runtime': 31.2638, 'eval_samples_per_second': 63.844, 'eval_steps_per_second': 7.996, 'epoch': 1.83}\n",
      "{'eval_loss': 0.3405584692955017, 'eval_content_rmse': 0.5159661173820496, 'eval_wording_rmse': 0.6441240310668945, 'eval_mcrmse': 0.5800451040267944, 'eval_runtime': 31.2773, 'eval_samples_per_second': 63.816, 'eval_steps_per_second': 7.993, 'epoch': 1.95}\n",
      "{'eval_loss': 0.36481574177742004, 'eval_content_rmse': 0.5096705555915833, 'eval_wording_rmse': 0.6854689717292786, 'eval_mcrmse': 0.5975697636604309, 'eval_runtime': 31.421, 'eval_samples_per_second': 63.524, 'eval_steps_per_second': 7.956, 'epoch': 2.07}\n",
      "{'eval_loss': 0.3767704367637634, 'eval_content_rmse': 0.5112709999084473, 'eval_wording_rmse': 0.7015292048454285, 'eval_mcrmse': 0.6064001321792603, 'eval_runtime': 31.4467, 'eval_samples_per_second': 63.473, 'eval_steps_per_second': 7.95, 'epoch': 2.19}\n",
      "{'eval_loss': 0.33771276473999023, 'eval_content_rmse': 0.5111216306686401, 'eval_wording_rmse': 0.6435683965682983, 'eval_mcrmse': 0.5773450136184692, 'eval_runtime': 31.5415, 'eval_samples_per_second': 63.282, 'eval_steps_per_second': 7.926, 'epoch': 2.31}\n",
      "{'eval_loss': 0.3519182503223419, 'eval_content_rmse': 0.5130144953727722, 'eval_wording_rmse': 0.6638168692588806, 'eval_mcrmse': 0.5884156823158264, 'eval_runtime': 31.4358, 'eval_samples_per_second': 63.495, 'eval_steps_per_second': 7.953, 'epoch': 2.43}\n",
      "{'eval_loss': 0.33129650354385376, 'eval_content_rmse': 0.5037380456924438, 'eval_wording_rmse': 0.6394065022468567, 'eval_mcrmse': 0.5715723037719727, 'eval_runtime': 31.3497, 'eval_samples_per_second': 63.669, 'eval_steps_per_second': 7.975, 'epoch': 2.56}\n",
      "{'loss': 0.2281, 'learning_rate': 1.5817223198594024e-06, 'epoch': 2.61}\n",
      "{'eval_loss': 0.3268221616744995, 'eval_content_rmse': 0.5201560258865356, 'eval_wording_rmse': 0.6189360022544861, 'eval_mcrmse': 0.5695459842681885, 'eval_runtime': 31.2486, 'eval_samples_per_second': 63.875, 'eval_steps_per_second': 8.0, 'epoch': 2.68}\n",
      "{'eval_loss': 0.3393113613128662, 'eval_content_rmse': 0.508785605430603, 'eval_wording_rmse': 0.6478888988494873, 'eval_mcrmse': 0.5783372521400452, 'eval_runtime': 31.3125, 'eval_samples_per_second': 63.744, 'eval_steps_per_second': 7.984, 'epoch': 2.8}\n",
      "{'eval_loss': 0.3370775282382965, 'eval_content_rmse': 0.5139575004577637, 'eval_wording_rmse': 0.6403144001960754, 'eval_mcrmse': 0.5771359205245972, 'eval_runtime': 31.3134, 'eval_samples_per_second': 63.743, 'eval_steps_per_second': 7.984, 'epoch': 2.92}\n",
      "{'train_runtime': 1900.6768, 'train_samples_per_second': 8.159, 'train_steps_per_second': 0.908, 'train_loss': 0.3089747951341712, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3:\n",
      "{'eval_loss': 0.5794399976730347, 'eval_content_rmse': 0.5541487336158752, 'eval_wording_rmse': 0.9229298830032349, 'eval_mcrmse': 0.7385393381118774, 'eval_runtime': 9.1024, 'eval_samples_per_second': 121.177, 'eval_steps_per_second': 15.161, 'epoch': 0.1}\n",
      "{'eval_loss': 0.5783413052558899, 'eval_content_rmse': 0.5390334129333496, 'eval_wording_rmse': 0.9306588172912598, 'eval_mcrmse': 0.7348461151123047, 'eval_runtime': 9.1865, 'eval_samples_per_second': 120.067, 'eval_steps_per_second': 15.022, 'epoch': 0.21}\n",
      "{'eval_loss': 0.896065354347229, 'eval_content_rmse': 0.7334596514701843, 'eval_wording_rmse': 1.1198965311050415, 'eval_mcrmse': 0.9266780614852905, 'eval_runtime': 8.5297, 'eval_samples_per_second': 129.313, 'eval_steps_per_second': 16.179, 'epoch': 0.31}\n",
      "{'eval_loss': 0.7315965890884399, 'eval_content_rmse': 0.6348586678504944, 'eval_wording_rmse': 1.0296345949172974, 'eval_mcrmse': 0.8322466611862183, 'eval_runtime': 8.492, 'eval_samples_per_second': 129.887, 'eval_steps_per_second': 16.251, 'epoch': 0.42}\n",
      "{'eval_loss': 0.8879718780517578, 'eval_content_rmse': 0.7864387035369873, 'eval_wording_rmse': 1.0758520364761353, 'eval_mcrmse': 0.9311453700065613, 'eval_runtime': 8.5168, 'eval_samples_per_second': 129.509, 'eval_steps_per_second': 16.203, 'epoch': 0.52}\n",
      "{'eval_loss': 0.7019410133361816, 'eval_content_rmse': 0.6637625098228455, 'eval_wording_rmse': 0.9814791679382324, 'eval_mcrmse': 0.8226208686828613, 'eval_runtime': 8.75, 'eval_samples_per_second': 126.056, 'eval_steps_per_second': 15.771, 'epoch': 0.62}\n",
      "{'eval_loss': 0.5851103067398071, 'eval_content_rmse': 0.6959329843521118, 'eval_wording_rmse': 0.8281896114349365, 'eval_mcrmse': 0.7620612978935242, 'eval_runtime': 8.5953, 'eval_samples_per_second': 128.326, 'eval_steps_per_second': 16.055, 'epoch': 0.73}\n",
      "{'loss': 0.426, 'learning_rate': 9.127436281859072e-06, 'epoch': 0.74}\n",
      "{'eval_loss': 0.433704137802124, 'eval_content_rmse': 0.5375315546989441, 'eval_wording_rmse': 0.7605707049369812, 'eval_mcrmse': 0.6490511298179626, 'eval_runtime': 8.6765, 'eval_samples_per_second': 127.125, 'eval_steps_per_second': 15.905, 'epoch': 0.83}\n",
      "{'eval_loss': 0.5792317390441895, 'eval_content_rmse': 0.6868838667869568, 'eval_wording_rmse': 0.8286455869674683, 'eval_mcrmse': 0.7577646970748901, 'eval_runtime': 8.6739, 'eval_samples_per_second': 127.164, 'eval_steps_per_second': 15.91, 'epoch': 0.93}\n",
      "{'eval_loss': 0.7709957957267761, 'eval_content_rmse': 0.8246704339981079, 'eval_wording_rmse': 0.9283908605575562, 'eval_mcrmse': 0.876530647277832, 'eval_runtime': 8.6555, 'eval_samples_per_second': 127.434, 'eval_steps_per_second': 15.944, 'epoch': 1.04}\n",
      "{'eval_loss': 0.7044614553451538, 'eval_content_rmse': 0.8330725431442261, 'eval_wording_rmse': 0.8455256819725037, 'eval_mcrmse': 0.8392990827560425, 'eval_runtime': 8.5643, 'eval_samples_per_second': 128.791, 'eval_steps_per_second': 16.113, 'epoch': 1.14}\n",
      "{'eval_loss': 0.4661233723163605, 'eval_content_rmse': 0.6166686415672302, 'eval_wording_rmse': 0.7429446578025818, 'eval_mcrmse': 0.679806649684906, 'eval_runtime': 8.6387, 'eval_samples_per_second': 127.682, 'eval_steps_per_second': 15.975, 'epoch': 1.25}\n",
      "{'eval_loss': 0.618500828742981, 'eval_content_rmse': 0.7524114847183228, 'eval_wording_rmse': 0.8190721869468689, 'eval_mcrmse': 0.7857418060302734, 'eval_runtime': 8.6528, 'eval_samples_per_second': 127.473, 'eval_steps_per_second': 15.949, 'epoch': 1.35}\n",
      "{'eval_loss': 0.4519934356212616, 'eval_content_rmse': 0.5776498913764954, 'eval_wording_rmse': 0.7551867961883545, 'eval_mcrmse': 0.6664183139801025, 'eval_runtime': 8.5148, 'eval_samples_per_second': 129.539, 'eval_steps_per_second': 16.207, 'epoch': 1.45}\n",
      "{'loss': 0.2589, 'learning_rate': 6.128935532233883e-06, 'epoch': 1.48}\n",
      "{'eval_loss': 0.563540518283844, 'eval_content_rmse': 0.6894872188568115, 'eval_wording_rmse': 0.8072722554206848, 'eval_mcrmse': 0.7483797073364258, 'eval_runtime': 8.6566, 'eval_samples_per_second': 127.417, 'eval_steps_per_second': 15.942, 'epoch': 1.56}\n",
      "{'eval_loss': 0.50313401222229, 'eval_content_rmse': 0.6994438171386719, 'eval_wording_rmse': 0.7190591096878052, 'eval_mcrmse': 0.7092514634132385, 'eval_runtime': 8.8071, 'eval_samples_per_second': 125.24, 'eval_steps_per_second': 15.669, 'epoch': 1.66}\n",
      "{'eval_loss': 0.7327342629432678, 'eval_content_rmse': 0.8308007717132568, 'eval_wording_rmse': 0.8804765939712524, 'eval_mcrmse': 0.8556386828422546, 'eval_runtime': 8.6878, 'eval_samples_per_second': 126.96, 'eval_steps_per_second': 15.884, 'epoch': 1.77}\n",
      "{'eval_loss': 0.7407156229019165, 'eval_content_rmse': 0.7968178391456604, 'eval_wording_rmse': 0.9200606942176819, 'eval_mcrmse': 0.8584392666816711, 'eval_runtime': 8.6993, 'eval_samples_per_second': 126.792, 'eval_steps_per_second': 15.863, 'epoch': 1.87}\n",
      "{'eval_loss': 0.48934999108314514, 'eval_content_rmse': 0.6782389283180237, 'eval_wording_rmse': 0.7202028036117554, 'eval_mcrmse': 0.6992208957672119, 'eval_runtime': 8.7445, 'eval_samples_per_second': 126.136, 'eval_steps_per_second': 15.781, 'epoch': 1.97}\n",
      "{'eval_loss': 0.4620104432106018, 'eval_content_rmse': 0.6770361065864563, 'eval_wording_rmse': 0.6823803782463074, 'eval_mcrmse': 0.6797082424163818, 'eval_runtime': 8.7031, 'eval_samples_per_second': 126.736, 'eval_steps_per_second': 15.856, 'epoch': 2.08}\n",
      "{'eval_loss': 0.4987930655479431, 'eval_content_rmse': 0.6985247731208801, 'eval_wording_rmse': 0.7138968110084534, 'eval_mcrmse': 0.7062107920646667, 'eval_runtime': 8.6703, 'eval_samples_per_second': 127.216, 'eval_steps_per_second': 15.916, 'epoch': 2.18}\n",
      "{'loss': 0.2292, 'learning_rate': 3.1304347826086955e-06, 'epoch': 2.23}\n",
      "{'eval_loss': 0.4785960912704468, 'eval_content_rmse': 0.6487219333648682, 'eval_wording_rmse': 0.7323606610298157, 'eval_mcrmse': 0.6905412673950195, 'eval_runtime': 8.5767, 'eval_samples_per_second': 128.605, 'eval_steps_per_second': 16.09, 'epoch': 2.28}\n",
      "{'eval_loss': 0.6061422824859619, 'eval_content_rmse': 0.7748792767524719, 'eval_wording_rmse': 0.7822067141532898, 'eval_mcrmse': 0.7785429954528809, 'eval_runtime': 8.6846, 'eval_samples_per_second': 127.007, 'eval_steps_per_second': 15.89, 'epoch': 2.39}\n",
      "{'eval_loss': 0.5473835468292236, 'eval_content_rmse': 0.7459119558334351, 'eval_wording_rmse': 0.733745813369751, 'eval_mcrmse': 0.739828884601593, 'eval_runtime': 8.6499, 'eval_samples_per_second': 127.517, 'eval_steps_per_second': 15.954, 'epoch': 2.49}\n",
      "{'eval_loss': 0.4667341709136963, 'eval_content_rmse': 0.6728867888450623, 'eval_wording_rmse': 0.6933193802833557, 'eval_mcrmse': 0.683103084564209, 'eval_runtime': 8.6221, 'eval_samples_per_second': 127.928, 'eval_steps_per_second': 16.005, 'epoch': 2.6}\n",
      "{'eval_loss': 0.533033549785614, 'eval_content_rmse': 0.7325897812843323, 'eval_wording_rmse': 0.7275847792625427, 'eval_mcrmse': 0.7300872802734375, 'eval_runtime': 8.8415, 'eval_samples_per_second': 124.753, 'eval_steps_per_second': 15.608, 'epoch': 2.7}\n",
      "{'eval_loss': 0.5305730104446411, 'eval_content_rmse': 0.7569339275360107, 'eval_wording_rmse': 0.6987107992172241, 'eval_mcrmse': 0.7278223633766174, 'eval_runtime': 8.7386, 'eval_samples_per_second': 126.221, 'eval_steps_per_second': 15.792, 'epoch': 2.8}\n",
      "{'eval_loss': 0.5101327896118164, 'eval_content_rmse': 0.7288182973861694, 'eval_wording_rmse': 0.6993489861488342, 'eval_mcrmse': 0.7140836715698242, 'eval_runtime': 8.7019, 'eval_samples_per_second': 126.753, 'eval_steps_per_second': 15.859, 'epoch': 2.91}\n",
      "{'loss': 0.1944, 'learning_rate': 1.3193403298350825e-07, 'epoch': 2.97}\n",
      "{'train_runtime': 1934.6068, 'train_samples_per_second': 9.4, 'train_steps_per_second': 1.045, 'train_loss': 0.2760581352354629, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv mcrmse: {'content_rmse': 0.5183165421949071, 'wording_rmse': 0.7267120956785867, 'mcrmse': 0.6225143189367469}\n"
     ]
    }
   ],
   "source": [
    "oof_train, test_pred  = get_oof_pred_n_test(train,\n",
    "                                            model_name=CFG.model_name,\n",
    "                                            learning_rate=CFG.learning_rate,\n",
    "                                            warmup_ratio=CFG.warmup_ratio,\n",
    "                                            hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "                                            attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "                                            num_layers_to_freeze=CFG.num_layers_to_freeze,\n",
    "                                            weight_decay=CFG.weight_decay,\n",
    "                                            num_train_epochs=CFG.num_train_epochs,\n",
    "                                            n_splits=CFG.n_splits,\n",
    "                                            batch_size=CFG.batch_size,\n",
    "                                            random_seed=CFG.random_seed,\n",
    "                                            save_steps=CFG.save_steps,\n",
    "                                            max_length=CFG.max_length\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c156d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000ffffff</td>\n",
       "      <td>-1.116083</td>\n",
       "      <td>-0.857669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111eeeeee</td>\n",
       "      <td>-1.116251</td>\n",
       "      <td>-0.863316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222222cccccc</td>\n",
       "      <td>-1.113319</td>\n",
       "      <td>-0.868946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333333dddddd</td>\n",
       "      <td>-1.117513</td>\n",
       "      <td>-0.873461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id   content   wording\n",
       "0  000000ffffff -1.116083 -0.857669\n",
       "1  111111eeeeee -1.116251 -0.863316\n",
       "2  222222cccccc -1.113319 -0.868946\n",
       "3  333333dddddd -1.117513 -0.873461"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = pd.read_csv(f\"test_pred.csv\")\n",
    "\n",
    "sample_submission[\"content\"] = test_pred.values[:, 0]\n",
    "sample_submission[\"wording\"] = test_pred.values[:, 1]\n",
    "\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31901621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e9cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
